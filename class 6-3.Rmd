---
title: "Class 6-3"
output: html_document
---

```{r setup, include=FALSE}
# install.packages("tidyverse")
# install.packages("mosaic")
# install.packages("ggplot2")
# install.packages("dplyr")
# install.packages("broom")
# install.packages("lattice")
# install.packages("gridExtra")
# install.packages("grid")
# install.packages("devtools")
# devtools::install_github("ProjectMOSAIC/mosaicModel")
# install.packages("pryr")

#library(pryr) # used for debugging function evaluation
library(tidyverse)
library(mosaic)
library(ggplot2)
library(dplyr)
library(broom)
library(lattice)
library(gridExtra)
library(grid)
library(mosaicModel) # newer version of statisticalModeling with better functions



```

#Load ads data

```{r}
ads_sales <- as_tibble(read.csv("Advertising.csv"))

```
# Simulating time I get to school

```{r}
commute_monte_carlo <- function(){
  wakeup <- 700 + rnorm(1, 10, 2)
  breakfast <- 10 + runif(1, -5, 5 )
  commute <- 20 + runif(1, 0, 10 )
  time_to_get_to_school <- wakeup + breakfast + commute
  
  #time_to_get_to_school <-  ...
  return(time_to_get_to_school)
}

simulate_1000_times <- do(1000)*commute_monte_carlo()
hist(simulate_1000_times$commute_monte_carlo)


profit_monte_carlo <- function(){
  # the price of ads fluctuates with the market
  # we model these price fluctuations with a random value
  ad_cost <- 9 + runif(1, -2, 10)
  number_of_ads <- 2
  expected_sales_per_ad_spending <- 1.04*number_of_ads
  
  profit <- expected_sales_per_ad_spending - (ad_cost*number_of_ads)
  return(profit)
}

simulate_1000_times <- do(1000)*profit_monte_carlo()
hist(simulate_1000_times$profit_monte_carlo)
```

# Simulating weight gain


# Simulating demand for housing in Seattle

```{r}
# population of seattle
# population of seattle that rents


# now, if we were economists, we could model price as function of demand
#   then we could predict rental/housing prices


# now the mayor announces a new plan to build 1,000 affordable units per month


```

# Simulating Ads decision


```{r}
model <- lm ( sales ~ TV * radio + newspaper, data=ads_sales)

# let's simulate a decision
first_sales_model <- mod_fun(model)

# the function below will return the outcome
# we'll start by simulating the decision with the outcome as
# the amount of sales, but we will reframe and simulate profits soon

# ****!
# this eval(substitute( )) hack to fix issues with argument evaluation
# with mod_fun only works one call level deep, unfortunately
simulate_decision <- function(choice_TV, choice_radio, choice_newspaper)
{
  #browser()
 eval(substitute(
   first_sales_model(TV=choice_TV, 
                    radio=choice_radio, 
                    newspaper=choice_newspaper)))
}

x<-simulate_decision(10,20,40)

# optim expects a single number so we need to get that out of the 
# tibble in the model_output column.
# We write simple wrapper function to convert to the interface optim wants
# note: I think this doesn't work b/c
#   substitute only looks one level up
#   e.g. https://github.com/hadley/lazyeval/blob/master/vignettes/lazyeval.Rmd
#   "substitute() only looks one level up, so you lose the original label if the function isn't called directly:"

sales_wrapper <- function(par){
  
  tv <- par[1]
  radio <- par[2]
  newsp <- par[3]
  if(tv+radio+newsp > 500 || tv+radio+newsp < 0)#budget
  {
    return(-1)
  } else {
   s <- eval(substitute(
   first_sales_model(TV=tv, 
                    radio=radio, 
                    newspaper=newsp)))
 
   s$model_output
   }
}




# optimize the choice - find the value of choice that gives highest function value
# ie find choice such that f(choice) is highest, for some values of choice
# ie 
optim(par=c(5,5,5), sales_wrapper, gr=NULL, method="L-BFGS-B",
      control = list(fnscale = -1))


# the price of ads fluctuates with the market
# we model these price fluctuations as a random variable


# change to make revenue_per_sale vary


# plot by revenue_per_sale


```

```{r}
fr <- function(x) {   ## Rosenbrock Banana function
    x1 <- x[1]
    x2 <- x[2]
    100 * (x2 - x1 * x1)^2 + (1 - x1)^2
}

y <- optim(par=c(0,0), fr, gr=NULL, method="L-BFGS-B",
      lower=rep(0, 3), upper=rep(200,3))
y

line <- function(x) {   ## Rosenbrock Banana function
    x1 <- x[1]
    x2 <- x[2]
    100 * x2 + x1
}

y <- optim(par=c(50,50), line, gr=NULL, method="L-BFGS-B",
      lower=rep(0, 3), upper=rep(200,3), control = list(fnscale = -1))
y
```

## Resample function

```{r}
?resample
fruit <- c("apple", "kiwi", "lemon", "orange", "pomegranate")
rep(1/length(fruit), times=length(fruit))
```

## Let's take some resamples from the fruit

You can also embed plots, for example:

```{r pressure, echo=FALSE}
fruit
resample(fruit)
resample(fruit)
resample(fruit)
resample(fruit)

```
We see that we don't always get the same sample. This is because resample is taking any row with equal probability, then doing it again. It can choose a row many times. If this makes you nervous, fear not, as the dataset size increases, the chance that you choose a row over and over (too much) is quite small.

Typically you should use 15,000 resamples to make a sampling distribution. With modern computers this is often quite feasible. (For big data, you can take a sample of your data 15,000 times.)

# "Bootstrapping" using 3 resamples as an example

```{r}
# let's use the ads dataset from last class
# let's make a confidence interval for the effect size of TV

approx_sampling_distribution_for_TV_effect <- tribble( ~slope)

resample1 <- resample(ads_sales)
model <- lm ( sales ~ TV + radio + newspaper, data=resample1)
slope <- mod_effect(model, ~ TV) %>% select(slope)
approx_sampling_distribution_for_TV_effect <- 
  bind_rows(approx_sampling_distribution_for_TV_effect,slope)


# how do we interpret effect size with multiple explanatory variables / interaction terms in the model
slope
approx_sampling_distribution_for_TV_effect

resample2 <- resample(ads_sales)
model <- lm ( sales ~ TV + radio + newspaper, data=resample2)
slope <- mod_effect(model, ~ TV) %>% select(slope)
approx_sampling_distribution_for_TV_effect <- 
  bind_rows(approx_sampling_distribution_for_TV_effect,slope)

slope
approx_sampling_distribution_for_TV_effect

# 14,998 more times ...
```
# mod_ensemble - makes <nreps> of models for you

```{r}
model <- lm ( sales ~ TV + radio + newspaper, data=ads_sales)
sales_mod_ensemble <- mod_ensemble(model, nreps = 2) 
approx_sampling_distribution_w_mod_ensemble <- 
  mod_effect(sales_mod_ensemble, ~ TV)



sales_mod_ensemble <- mod_ensemble(model, nreps = 100) 
approx_sampling_distribution <- 
  mod_effect(sales_mod_ensemble, ~ TV)

approx_sampling_distribution
hist(approx_sampling_distribution$slope)

# helper function that computes the coverage interval / confidence interval at the desired level
cover95 <- coverage(0.95)

# get confidence interval
# the strange syntax is to let you see interaction effects
#
approx_sampling_distribution %>%
  df_stats(~ TV, cover95)

# you can also parametric formulas
lower_ci =  mean (approx_sampling_distribution$slope) - 1.96*sd(approx_sampling_distribution)
upper_ci =  mean (approx_sampling_distribution$slope) + 1.96*sd(approx_sampling_distribution)


#nice to have: compare to the theoretical CI
approx_sampling_distribution
 

```


# Bootstrapping with 15k resamples

```{r}
set.seed(42) #reproducibility - the answer to everything

# bootstrapping with 15,000 resamples
sales_mod_ensemble <- mod_ensemble(model, nreps = 15000) 
approx_sampling_distribution <- 
  mod_effect(sales_mod_ensemble, ~ TV)

tidy(summary(model))
#pro-tip: keep this separate or load an R data file to save yourself time
#alternative: built-in coffee breaks for your scripts

```
# Let's visualize the approx. sampling distribution for effect size

```{r}
hist(approx_sampling_distribution$slope)
```
# Let's simulate some random linear data

```{r}
actual_slope <- .6
actual_intercept <- 10

runif(3, 0, 1)
rnorm(3)
rnorm(3, 0, 1)
# for (nrep in 1:10000 )
random_dataset <-actual_intercept + actual_slope * runif(100, 0, 20)

hist(approx_sampling_distribution$slope)
```
